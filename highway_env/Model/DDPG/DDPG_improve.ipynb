{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1iCKcbMh5BB",
        "outputId": "fe61fd82-f115-451a-a7ff-af64afb6c054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting highway-env\n",
            "  Downloading highway_env-1.10.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.4.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.5.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.10.0.84)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.17.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.66.6)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Collecting ale-py>=0.9.0 (from stable-baselines3[extra])\n",
            "  Downloading ale_py-0.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (11.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from highway-env) (1.13.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.68.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading highway_env-1.10.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ale_py-0.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading stable_baselines3-2.4.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: farama-notifications, gymnasium, ale-py, stable-baselines3, highway-env\n",
            "Successfully installed ale-py-0.10.1 farama-notifications-0.0.4 gymnasium-1.0.0 highway-env-1.10.1 stable-baselines3-2.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3[extra] gymnasium highway-env"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Callback to Log Training Performance\n",
        "class RewardLoggingCallback(BaseCallback):\n",
        "    def __init__(self, verbose=0):\n",
        "        super(RewardLoggingCallback, self).__init__(verbose)\n",
        "        self.episode_rewards = []  # Store episode rewards\n",
        "        self.episode_lengths = []  # Store episode lengths\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        # Check if a new episode has started\n",
        "        if \"episode\" in self.locals:\n",
        "            reward = self.locals[\"infos\"][0][\"episode\"][\"r\"]\n",
        "            length = self.locals[\"infos\"][0][\"episode\"][\"l\"]\n",
        "            self.episode_rewards.append(reward)\n",
        "            self.episode_lengths.append(length)\n",
        "        return True"
      ],
      "metadata": {
        "id": "U-gKCgu6s5oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8_PxhA5iAyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c632d3c4-3b9d-49d3-fc9c-2ba0f276453e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3 import DDPG\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n",
        "import highway_env\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cwDrOHHivnr"
      },
      "outputs": [],
      "source": [
        "# Create the environment\n",
        "env = gym.make(\"highway-v0\")\n",
        "\n",
        "env.unwrapped.configure({\n",
        "    \"action\": {\n",
        "        \"type\": \"ContinuousAction\",  # Use continuous action space\n",
        "    },\n",
        "    \"simulation_frequency\": 15\n",
        "})\n",
        "\n",
        "# Reset the environment\n",
        "obs, info = env.reset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdlLoCNfDBp5"
      },
      "source": [
        "\n",
        "# **Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V67pEagl5Zp",
        "outputId": "1663fae6-88b7-4b49-abb5-d6fa6463acc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Logging to ./ddpg_highway_tensorboard/DDPG_1\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 8.22     |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 88       |\n",
            "|    total_timesteps | 160      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.368   |\n",
            "|    critic_loss     | 0.00899  |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 59       |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 16.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 178      |\n",
            "|    total_timesteps | 320      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.909   |\n",
            "|    critic_loss     | 0.0331   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 219      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 14.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 266      |\n",
            "|    total_timesteps | 480      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.95    |\n",
            "|    critic_loss     | 0.0271   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 379      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 13.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 357      |\n",
            "|    total_timesteps | 640      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.3     |\n",
            "|    critic_loss     | 0.0461   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 539      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 14.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 446      |\n",
            "|    total_timesteps | 800      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.84    |\n",
            "|    critic_loss     | 0.071    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 699      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 15.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 536      |\n",
            "|    total_timesteps | 960      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -2.37    |\n",
            "|    critic_loss     | 0.248    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 859      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 15.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 625      |\n",
            "|    total_timesteps | 1120     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.09    |\n",
            "|    critic_loss     | 0.324    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 1019     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 16.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 716      |\n",
            "|    total_timesteps | 1280     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.35    |\n",
            "|    critic_loss     | 0.197    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 1179     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 17.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 806      |\n",
            "|    total_timesteps | 1440     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -4.38    |\n",
            "|    critic_loss     | 0.143    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 1339     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 17.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 897      |\n",
            "|    total_timesteps | 1600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.35    |\n",
            "|    critic_loss     | 0.0946   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 1499     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 17.6     |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 988      |\n",
            "|    total_timesteps | 1760     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.51    |\n",
            "|    critic_loss     | 0.13     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 1659     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 18.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 1077     |\n",
            "|    total_timesteps | 1920     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.99    |\n",
            "|    critic_loss     | 0.189    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 1819     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 19.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 1168     |\n",
            "|    total_timesteps | 2080     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -6.58    |\n",
            "|    critic_loss     | 0.168    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 1979     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 20       |\n",
            "| time/              |          |\n",
            "|    episodes        | 56       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 1261     |\n",
            "|    total_timesteps | 2240     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.36    |\n",
            "|    critic_loss     | 0.199    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 2139     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 20.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 1351     |\n",
            "|    total_timesteps | 2400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -8.73    |\n",
            "|    critic_loss     | 0.111    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 2299     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 21.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 64       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 1442     |\n",
            "|    total_timesteps | 2560     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -8.96    |\n",
            "|    critic_loss     | 0.125    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 2459     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 22       |\n",
            "| time/              |          |\n",
            "|    episodes        | 68       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 1531     |\n",
            "|    total_timesteps | 2720     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.93    |\n",
            "|    critic_loss     | 0.311    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 2619     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 22.3     |\n",
            "| time/              |          |\n",
            "|    episodes        | 72       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 1622     |\n",
            "|    total_timesteps | 2880     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -10.3    |\n",
            "|    critic_loss     | 0.21     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 2779     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 22.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 76       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 1710     |\n",
            "|    total_timesteps | 3040     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -11.5    |\n",
            "|    critic_loss     | 0.163    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 2939     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 23       |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 1801     |\n",
            "|    total_timesteps | 3200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -12      |\n",
            "|    critic_loss     | 0.118    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 3099     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 23.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 84       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 1891     |\n",
            "|    total_timesteps | 3360     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -12.5    |\n",
            "|    critic_loss     | 0.276    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 3259     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 23.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 88       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 1981     |\n",
            "|    total_timesteps | 3520     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -13.8    |\n",
            "|    critic_loss     | 0.21     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 3419     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 23.6     |\n",
            "| time/              |          |\n",
            "|    episodes        | 92       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 2072     |\n",
            "|    total_timesteps | 3680     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.5    |\n",
            "|    critic_loss     | 0.355    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 3579     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 23.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 96       |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 2162     |\n",
            "|    total_timesteps | 3840     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -15.6    |\n",
            "|    critic_loss     | 0.218    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 3739     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 24.1     |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 2253     |\n",
            "|    total_timesteps | 4000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16      |\n",
            "|    critic_loss     | 0.109    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 3899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 24.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 104      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 2342     |\n",
            "|    total_timesteps | 4160     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16.5    |\n",
            "|    critic_loss     | 0.348    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 4059     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 25.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 108      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 2433     |\n",
            "|    total_timesteps | 4320     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16.7    |\n",
            "|    critic_loss     | 0.147    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 4219     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 26       |\n",
            "| time/              |          |\n",
            "|    episodes        | 112      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 2525     |\n",
            "|    total_timesteps | 4480     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -17.6    |\n",
            "|    critic_loss     | 0.134    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 4379     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 26.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 116      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 2617     |\n",
            "|    total_timesteps | 4640     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -18.5    |\n",
            "|    critic_loss     | 0.112    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 4539     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 27.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 2707     |\n",
            "|    total_timesteps | 4800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.1    |\n",
            "|    critic_loss     | 0.0588   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 4699     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 27.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 124      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 2797     |\n",
            "|    total_timesteps | 4960     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.5    |\n",
            "|    critic_loss     | 0.307    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 4859     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 28.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 128      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 2888     |\n",
            "|    total_timesteps | 5120     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.8    |\n",
            "|    critic_loss     | 0.18     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 5019     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 29       |\n",
            "| time/              |          |\n",
            "|    episodes        | 132      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 2979     |\n",
            "|    total_timesteps | 5280     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -21.2    |\n",
            "|    critic_loss     | 0.174    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 5179     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 29.1     |\n",
            "| time/              |          |\n",
            "|    episodes        | 136      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 3069     |\n",
            "|    total_timesteps | 5440     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -21.5    |\n",
            "|    critic_loss     | 0.175    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 5339     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 29.7     |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 3160     |\n",
            "|    total_timesteps | 5600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -22.1    |\n",
            "|    critic_loss     | 0.156    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 5499     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 30.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 144      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 3250     |\n",
            "|    total_timesteps | 5760     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -22.9    |\n",
            "|    critic_loss     | 0.107    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 5659     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 30.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 148      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 3341     |\n",
            "|    total_timesteps | 5920     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -22.9    |\n",
            "|    critic_loss     | 0.206    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 5819     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 30.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 152      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 3432     |\n",
            "|    total_timesteps | 6080     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -24      |\n",
            "|    critic_loss     | 0.182    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 5979     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 30.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 156      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 3522     |\n",
            "|    total_timesteps | 6240     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -24.3    |\n",
            "|    critic_loss     | 0.248    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 6139     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 30.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 3614     |\n",
            "|    total_timesteps | 6400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -25      |\n",
            "|    critic_loss     | 0.161    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 6299     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 30.6     |\n",
            "| time/              |          |\n",
            "|    episodes        | 164      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 3703     |\n",
            "|    total_timesteps | 6560     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -25.9    |\n",
            "|    critic_loss     | 0.0807   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 6459     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 30.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 168      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 3794     |\n",
            "|    total_timesteps | 6720     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -26.3    |\n",
            "|    critic_loss     | 0.107    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 6619     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 30.6     |\n",
            "| time/              |          |\n",
            "|    episodes        | 172      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 3885     |\n",
            "|    total_timesteps | 6880     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -26.7    |\n",
            "|    critic_loss     | 0.108    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 6779     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 30.9     |\n",
            "| time/              |          |\n",
            "|    episodes        | 176      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 3975     |\n",
            "|    total_timesteps | 7040     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -28      |\n",
            "|    critic_loss     | 0.174    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 6939     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 30.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 180      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 4067     |\n",
            "|    total_timesteps | 7200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -28.3    |\n",
            "|    critic_loss     | 0.124    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 7099     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 30.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 184      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 4156     |\n",
            "|    total_timesteps | 7360     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -28.6    |\n",
            "|    critic_loss     | 0.102    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 7259     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 31.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 188      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 4248     |\n",
            "|    total_timesteps | 7520     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -29.5    |\n",
            "|    critic_loss     | 0.0595   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 7419     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 31.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 192      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 4339     |\n",
            "|    total_timesteps | 7680     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30      |\n",
            "|    critic_loss     | 0.157    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 7579     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 31.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 196      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 4429     |\n",
            "|    total_timesteps | 7840     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.3    |\n",
            "|    critic_loss     | 0.109    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 7739     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 31.3     |\n",
            "| time/              |          |\n",
            "|    episodes        | 200      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 4519     |\n",
            "|    total_timesteps | 8000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.8    |\n",
            "|    critic_loss     | 0.419    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 7899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 31.6     |\n",
            "| time/              |          |\n",
            "|    episodes        | 204      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 4609     |\n",
            "|    total_timesteps | 8160     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.7    |\n",
            "|    critic_loss     | 0.16     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 8059     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 31.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 208      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 4700     |\n",
            "|    total_timesteps | 8320     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.9    |\n",
            "|    critic_loss     | 0.137    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 8219     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 31.4     |\n",
            "| time/              |          |\n",
            "|    episodes        | 212      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 4789     |\n",
            "|    total_timesteps | 8480     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.2    |\n",
            "|    critic_loss     | 0.321    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 8379     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 31.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 216      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 4881     |\n",
            "|    total_timesteps | 8640     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.1    |\n",
            "|    critic_loss     | 0.261    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 8539     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 31.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 220      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 4972     |\n",
            "|    total_timesteps | 8800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34      |\n",
            "|    critic_loss     | 0.1      |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 8699     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 31.6     |\n",
            "| time/              |          |\n",
            "|    episodes        | 224      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 5061     |\n",
            "|    total_timesteps | 8960     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.2    |\n",
            "|    critic_loss     | 0.197    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 8859     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 31.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 228      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 5151     |\n",
            "|    total_timesteps | 9120     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.9    |\n",
            "|    critic_loss     | 0.171    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 9019     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 31.6     |\n",
            "| time/              |          |\n",
            "|    episodes        | 232      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 5241     |\n",
            "|    total_timesteps | 9280     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.8    |\n",
            "|    critic_loss     | 0.182    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 9179     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 31.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 236      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 5333     |\n",
            "|    total_timesteps | 9440     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.5    |\n",
            "|    critic_loss     | 0.159    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 9339     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 31.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 240      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 5424     |\n",
            "|    total_timesteps | 9600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.8    |\n",
            "|    critic_loss     | 0.147    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 9499     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 31.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 244      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 5514     |\n",
            "|    total_timesteps | 9760     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.1    |\n",
            "|    critic_loss     | 0.0827   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 9659     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 40       |\n",
            "|    ep_rew_mean     | 31.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 248      |\n",
            "|    fps             | 1        |\n",
            "|    time_elapsed    | 5605     |\n",
            "|    total_timesteps | 9920     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.3    |\n",
            "|    critic_loss     | 0.0859   |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 9819     |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ddpg.ddpg.DDPG at 0x786173e82650>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Create action noise for exploration\n",
        "n_actions = env.action_space.shape[0]\n",
        "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
        "\n",
        "# Create the DDPG model\n",
        "model = DDPG(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    action_noise=action_noise,\n",
        "    learning_rate=0.001,\n",
        "    gamma=0.99,\n",
        "    buffer_size=1000000,\n",
        "    tau=0.005,\n",
        "    batch_size=64,\n",
        "    verbose=1,\n",
        "    tensorboard_log=\"./ddpg_highway_tensorboard/\"\n",
        ")\n",
        "\n",
        "# Initialize the callback\n",
        "reward_logger = RewardLoggingCallback()\n",
        "\n",
        "# Train the model\n",
        "model.learn(total_timesteps=20000, callback=reward_logger)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkGhQhxAc_wN"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuxhmXaWdA_u"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZyxEHrVdCPx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2-eeTtcospy",
        "outputId": "93a8558d-78ec-4ba4-bb10-897bcca8e6c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Save rewards after the first 20k timesteps\n",
        "np.save(\"/content/drive/My Drive/ddpg_rewards_10k.npy\", reward_logger.episode_rewards)\n",
        "print(\"Rewards after 20k timesteps saved!\")\n",
        "\n",
        "\n",
        "# Save the model\n",
        "model.save(\"/content/drive/My Drive/ddpg_highway\")\n",
        "\n",
        "# Save the replay buffer\n",
        "model.save_replay_buffer(\"/content/drive/My Drive/ddpg_replay_buffer\")\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from stable_baselines3 import DDPG\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reload environment\n",
        "env = gym.make(\"highway-v0\")\n",
        "env.unwrapped.configure({\n",
        "    \"action\": {\n",
        "        \"type\": \"ContinuousAction\",  # Use continuous action space\n",
        "    },\n",
        "    \"simulation_frequency\": 15\n",
        "})\n",
        "obs, info = env.reset()\n",
        "\n",
        "# Load the model and replay buffer\n",
        "model = DDPG.load(\"/content/drive/My Drive/ddpg_highway\", env=env)\n",
        "model.load_replay_buffer(\"/content/drive/My Drive/ddpg_replay_buffer\")\n",
        "print(\"Model and replay buffer loaded successfully!\")\n",
        "\n",
        "# Load previously saved rewards\n",
        "old_rewards = []\n",
        "try:\n",
        "    old_rewards = np.load(\"/content/drive/My Drive/ddpg_rewards_20k.npy\").tolist()\n",
        "    print(\"Previous rewards loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"No previous rewards found. Starting fresh.\")\n",
        "\n",
        "# Initialize new reward logger\n",
        "reward_logger = RewardLoggingCallback()\n",
        "\n",
        "# Continue training\n",
        "model.learn(total_timesteps=10000, callback=reward_logger)\n",
        "\n",
        "# Combine old and new rewards\n",
        "combined_rewards = old_rewards + reward_logger.episode_rewards\n",
        "\n",
        "# Save updated model, buffer, and rewards\n",
        "model.save(\"/content/drive/My Drive/ddpg_highway\")\n",
        "model.save_replay_buffer(\"/content/drive/My Drive/ddpg_replay_buffer\")\n",
        "np.save(\"/content/drive/My Drive/ddpg_rewards_30k.npy\", combined_rewards)\n",
        "print(\"Training complete! Model, replay buffer, and rewards updated.\")\n",
        "\n",
        "# Plot combined rewards\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(combined_rewards)\n",
        "plt.title(\"Training Performance (Episode Rewards)\")\n",
        "plt.xlabel(\"Episodes\")\n",
        "plt.ylabel(\"Rewards\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KrSDofQet029"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDrRPsj0BwEQ"
      },
      "outputs": [],
      "source": [
        "# Load TensorBoard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./ddpg_highway_tensorboard/DDPG_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azP39PbODQ9l"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Read TensorBoard logs using Pandas\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "\n",
        "def extract_tensorboard_data(logdir, scalar_name):\n",
        "    # Load the TensorBoard log file\n",
        "    event_acc = EventAccumulator(logdir)\n",
        "    event_acc.Reload()\n",
        "    scalar_events = event_acc.Scalars(scalar_name)\n",
        "    steps = [event.step for event in scalar_events]\n",
        "    values = [event.value for event in scalar_events]\n",
        "    return steps, values\n",
        "\n",
        "# Path to TensorBoard log file\n",
        "logdir = \"./ddpg_highway_tensorboard/DDPG_1\"\n",
        "scalar_name = \"rollout/ep_rew_mean\"  # Average reward\n",
        "\n",
        "# Extract data\n",
        "steps, rewards = extract_tensorboard_data(logdir, scalar_name)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(steps, rewards, label=\"Reward Curve\", color=\"b\")\n",
        "plt.xlabel(\"Timesteps\")\n",
        "plt.ylabel(\"Mean Reward\")\n",
        "plt.title(\"Training Performance: DDPG on Highway-v0\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAmxLNv0pKt4"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3 import DDPG\n",
        "import highway_env\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Reload the environment and model\n",
        "env = gym.make(\"highway-v0\")\n",
        "env.unwrapped.configure({\n",
        "    \"action\": {\n",
        "        \"type\": \"ContinuousAction\",  # Use continuous action space\n",
        "    },\n",
        "    \"simulation_frequency\": 15\n",
        "})\n",
        "obs, info = env.reset()\n",
        "\n",
        "# Load the trained model\n",
        "model = DDPG.load(\"ddpg_highway_improve\", env=env)\n",
        "\n",
        "# Lists to log rewards and timesteps\n",
        "timestep_rewards = []\n",
        "cumulative_rewards = []\n",
        "timesteps = []\n",
        "\n",
        "# Run and test the model\n",
        "current_timestep = 0\n",
        "\n",
        "for episode in range(100):  # Test over 10 episodes\n",
        "    done = truncated = False\n",
        "    obs, info = env.reset()\n",
        "    total_reward = 0\n",
        "\n",
        "    while not (done or truncated):\n",
        "        # Predict action using the trained model\n",
        "        action, _states = model.predict(obs, deterministic=True)\n",
        "        obs, reward, done, truncated, info = env.step(action)\n",
        "\n",
        "        total_reward += reward\n",
        "        current_timestep += 1\n",
        "        env.render()  # Visualize the environment\n",
        "\n",
        "        # Log timestep data\n",
        "        timestep_rewards.append(reward)\n",
        "        timesteps.append(current_timestep)\n",
        "\n",
        "    cumulative_rewards.append(total_reward)\n",
        "    print(f\"Episode {episode + 1}: Reward = {total_reward}\")\n",
        "\n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEaH4TmnBsg-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Cumulative Rewards Plot\n",
        "episodes = range(1, len(cumulative_rewards) + 1)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(episodes, cumulative_rewards, marker='o', label=\"Cumulative Reward per Episode\")\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Cumulative Reward\")\n",
        "plt.title(\"Model Performance Over Episodes\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}